import asyncio
import time     
import uuid
from typing import List, Optional

# å¯¼å…¥é¡¹ç›®ç›¸å…³çš„æ¨¡å—
from agent.base.protocal import MySample
from agent.gym_rollout_datasource import GymRolloutDataSource  # æ•°æ®æº
from agent.gym_rollout import agent_loop_generate, compute_group_advantages  # æ•°æ®ç”Ÿæˆå‡½æ•°
from slime.rollout.sglang_rollout import GenerateState  # ç”ŸæˆçŠ¶æ€ç®¡ç†


class RolloutProducer:
    """
    1. åœ¨åå°æŒç»­ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆä¸é˜»å¡è®­ç»ƒè¿‡ç¨‹ï¼‰
    2. å°†ç”Ÿæˆçš„æ•°æ®æ”¾å…¥é˜Ÿåˆ—ä¸­ä¾›æ¶ˆè´¹è€…ä½¿ç”¨
    3. å®ç°èƒŒå‹æ§åˆ¶ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
    """
    
    def __init__(self, args, queue: asyncio.Queue, data_source: GymRolloutDataSource):
        """
        - args: é…ç½®å‚æ•°ï¼ˆåŒ…å«æ‰¹æ¬¡å¤§å°ã€æ¨¡å‹å‚æ•°ç­‰ï¼‰
        - queue: å¼‚æ­¥é˜Ÿåˆ—ï¼Œç”¨äºå­˜å‚¨ç”Ÿæˆçš„æ•°æ®
        - data_source: æ•°æ®æºï¼Œæä¾›åŸå§‹çš„promptæ•°æ®
        """
        self.args = args  # ä¿å­˜é…ç½®å‚æ•°
        self.queue = queue  # æ•°æ®é˜Ÿåˆ—ï¼ˆç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…çš„æ¡¥æ¢ï¼‰
        self.data_source = data_source  # æ•°æ®æº
        self.state = GenerateState(args)  # ç”ŸæˆçŠ¶æ€ç®¡ç†å™¨
        
        # ç”Ÿäº§è€…çŠ¶æ€æ§åˆ¶
        self.is_running = False  # æ˜¯å¦æ­£åœ¨è¿è¡Œ
        self.producer_task: Optional[asyncio.Task] = None  # ç”Ÿäº§ä»»åŠ¡çš„å¼•ç”¨
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_produced = 0  # æ€»å…±ç”Ÿäº§çš„æ ·æœ¬æ•°
        self.total_groups_produced = 0  # æ€»å…±ç”Ÿäº§çš„ç»„æ•°
        
        # é˜²æ­¢ç”Ÿäº§è€…ç”Ÿæˆè¿‡å¤šæ•°æ®å¯¼è‡´å†…å­˜æº¢å‡º
        self.max_queue_size = args.global_batch_size * 10  # 10ä¸ªæ‰¹æ¬¡çš„ç¼“å†²å®¹é‡
        
    async def start(self):
        """
        1. åˆ›å»ºä¸€ä¸ªåå°ä»»åŠ¡æ¥æŒç»­ç”Ÿæˆæ•°æ®
        2. ç«‹å³è¿”å›ï¼Œä¸é˜»å¡è°ƒç”¨è€…
        3. ç”Ÿäº§è€…å°†åœ¨åå°ç‹¬ç«‹è¿è¡Œ
        
        å¼‚æ­¥è§£è€¦çš„ä½“ç°ï¼š
        - è°ƒç”¨start()åç«‹å³è¿”å›ï¼Œä¸ç­‰å¾…æ•°æ®ç”Ÿæˆå®Œæˆ
        - ç”Ÿäº§è€…åœ¨åå°æŒç»­å·¥ä½œï¼Œä¸è®­ç»ƒè¿‡ç¨‹å¹¶è¡Œ
        """
        if self.is_running:
            print("Producer already running, skipping start")
            return
            
        self.is_running = True
        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡ï¼Œè®©ç”Ÿäº§è€…åœ¨åå°è¿è¡Œ
        self.producer_task = asyncio.create_task(self._produce_loop())
        print(f"RolloutProducer started, will continuously produce data in background")
        
    async def stop(self):
        """
        1. è®¾ç½®åœæ­¢æ ‡å¿—
        2. å–æ¶ˆåå°ç”Ÿäº§ä»»åŠ¡
        3. ç­‰å¾…ä»»åŠ¡å®Œå…¨ç»“æŸ
        4. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        """
        self.is_running = False
        
        if self.producer_task:
            # å–æ¶ˆåå°ä»»åŠ¡
            self.producer_task.cancel()
            try:
                # ç­‰å¾…ä»»åŠ¡å®Œå…¨ç»“æŸ
                await self.producer_task
            except asyncio.CancelledError:
                # è¿™æ˜¯æ­£å¸¸çš„å–æ¶ˆæ“ä½œï¼Œä¸æ˜¯é”™è¯¯
                pass
                
        print(f"RolloutProducer stopped, total produced: {self.total_produced} samples")
        
    async def _produce_loop(self):
        """
        1. æŒç»­æ•°æ®ç”Ÿæˆï¼šä¸åœåœ°ç”Ÿæˆæ–°çš„è®­ç»ƒæ•°æ®
        2. èƒŒå‹æ§åˆ¶ï¼šé˜Ÿåˆ—æ»¡æ—¶æš‚åœï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
        3. å¼‚æ­¥æ“ä½œï¼šä½¿ç”¨awaitç¡®ä¿ä¸é˜»å¡å…¶ä»–ä»»åŠ¡
        4. é”™è¯¯å¤„ç†ï¼šæ•è·å¼‚å¸¸å¹¶ä¼˜é›…å¤„ç†
        """
        try:
            print("Producer loop started, beginning continuous data generation")
            
            while self.is_running:
                # é˜Ÿåˆ—æ»¡æ—¶æš‚åœç”Ÿäº§ï¼›é˜²æ­¢äº†å†…å­˜æ— é™å¢é•¿
                if self.queue.qsize() >= self.max_queue_size:
                    print(f"Queue full ({self.queue.qsize()}/{self.max_queue_size}), producer pausing...")
                    await asyncio.sleep(0.1)  # çŸ­æš‚ä¼‘æ¯ï¼Œè®©æ¶ˆè´¹è€…æœ‰æœºä¼šæ¶ˆè´¹æ•°æ®
                    continue
                    
                # ä»æ•°æ®æºè·å–åŸå§‹promptæ•°æ®
                prompt_groups = self.data_source.get_samples(1)
                if not prompt_groups:
                    print("No more prompts available, producer stopping naturally")
                    break
                    
                prompt_group = prompt_groups[0]
                # ç”Ÿæˆå”¯ä¸€çš„ç»„IDï¼Œç”¨äºè·Ÿè¸ªå’Œè°ƒè¯•
                prompt_group_id = f"producer_group_{uuid.uuid4().hex[:8]}"
                
                print(f"Processing prompt group {prompt_group_id} with {len(prompt_group)} prompts")
                
                # ä¸ºæ¯ä¸ªpromptç”ŸæˆAIå“åº”è½¨è¿¹ï¼ˆtrajectoriesï¼‰
                tasks = []
                for i, prompt_sample in enumerate(prompt_group):
                    trajectory_id = f"{prompt_group_id}_traj_{i}"
                    # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡æ¥ç”ŸæˆAIå“åº”
                    task = agent_loop_generate(
                        self.args,
                        prompt_sample,
                        trajectory_id=trajectory_id,
                        prompt_group_id=prompt_group_id,
                        sampling_params=self.state.sampling_params.copy()
                    )
                    tasks.append(task)
                
                print(f"Generating {len(tasks)} trajectories concurrently...")
                # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è½¨è¿¹ç”Ÿæˆä»»åŠ¡
                trajectory_results = await asyncio.gather(*tasks)
                
                # è®¡ç®—ç»„å†…ä¼˜åŠ¿å€¼
                print("Computing group advantages...")
                advs = compute_group_advantages(trajectory_results, self.args)
                for samples, adv in zip(trajectory_results, advs):
                    for samp in samples:
                        samp.advantage = adv
                
                # å±•å¹³æ‰€æœ‰è½¨è¿¹æ•°æ®ä¸ºå•ä¸ªåˆ—è¡¨
                all_steps = [step for trajectory_steps in trajectory_results for step in trajectory_steps]
                
                if all_steps:
                    # ç”Ÿæˆçš„æ•°æ®æ”¾å…¥é˜Ÿåˆ—
                    await self.queue.put(all_steps)
                    self.total_produced += len(all_steps)
                    self.total_groups_produced += 1
                    
                    print(f"Producer: generated group {self.total_groups_produced}, "
                          f"{len(all_steps)} steps, queue size: {self.queue.qsize()}/{self.max_queue_size}")
                    print(f"Total produced so far: {self.total_produced} samples")
                    
        except Exception as e:
            print(f"Producer error: {e}")
            import traceback
            traceback.print_exc()
            raise
        finally:
            # Noneä½œä¸ºç‰¹æ®Šä¿¡å·ï¼Œå‘Šè¯‰æ¶ˆè´¹è€…æ²¡æœ‰æ›´å¤šæ•°æ®äº†
            print("Producer finishing, sending end signal...")
            await self.queue.put(None)  # Noneä½œä¸ºç»“æŸä¿¡å·
            print(f"Producer finished successfully!")
            print(f"Final statistics: {self.total_produced} steps, {self.total_groups_produced} groups")


class RolloutConsumer:
    """
    1. ä»é˜Ÿåˆ—ä¸­å¿«é€Ÿè·å–å·²ç”Ÿæˆçš„æ•°æ®
    2. æ”¯æŒéé˜»å¡è·å–ï¼Œä¸ç­‰å¾…æ•°æ®ç”Ÿæˆ
    3. å®ç°é¢„å¡«å……æœºåˆ¶ï¼Œç¡®ä¿è®­ç»ƒå¼€å§‹æ—¶å°±æœ‰è¶³å¤Ÿæ•°æ®
    4. å¤„ç†å‰©ä½™æ•°æ®ï¼Œç¡®ä¿é›¶æµªè´¹
    """
    
    def __init__(self, queue: asyncio.Queue, args):
        """
        åˆå§‹åŒ–æ¶ˆè´¹è€…
        
        å‚æ•°è§£é‡Šï¼š
        - queue: ä¸ç”Ÿäº§è€…å…±äº«çš„æ•°æ®é˜Ÿåˆ—
        - args: é…ç½®å‚æ•°ï¼ˆåŒ…å«æ‰¹æ¬¡å¤§å°ç­‰ï¼‰
        """
        self.queue = queue  # æ•°æ®é˜Ÿåˆ—ï¼ˆä¸ç”Ÿäº§è€…å…±äº«ï¼‰
        self.args = args  # é…ç½®å‚æ•°
        self.is_finished = False  # æ˜¯å¦æ¥æ”¶åˆ°ç»“æŸä¿¡å·
        self.total_consumed = 0  # æ€»å…±æ¶ˆè´¹çš„æ ·æœ¬æ•°
        
        # ç¡®ä¿è®­ç»ƒå¼€å§‹æ—¶é˜Ÿåˆ—ä¸­å·²æœ‰è¶³å¤Ÿæ•°æ®ï¼Œé¿å…ç­‰å¾…
        self.min_prefill_batches = 3  # æœ€å°é¢„å¡«å……3ä¸ªæ‰¹æ¬¡
        print(f"RolloutConsumer initialized, will prefill {self.min_prefill_batches} batches")
        
    async def ensure_queue_ready(self):
        """        
        1. ç­‰å¾…ç”Ÿäº§è€…ç”Ÿæˆè¶³å¤Ÿçš„æ•°æ®
        2. ç¡®ä¿è®­ç»ƒå¼€å§‹æ—¶é˜Ÿåˆ—ä¸­æœ‰è¶³å¤Ÿçš„ç¼“å†²æ•°æ®
        3. é¿å…è®­ç»ƒè¿‡ç¨‹ä¸­å› ç­‰å¾…æ•°æ®è€Œé˜»å¡
        """
        # è®¡ç®—éœ€è¦é¢„å¡«å……çš„æœ€å°æ ·æœ¬æ•°
        min_samples = self.min_prefill_batches * self.args.global_batch_size
        print(f"Consumer: waiting for queue to prefill (target: {min_samples} samples)...")
        print(f"   - This ensures training can start immediately without waiting")
        
        start_time = time.time()
        
        # ç­‰å¾…é˜Ÿåˆ—è¾¾åˆ°æœ€å°é¢„å¡«å……é‡
        while self.queue.qsize() < min_samples and not self.is_finished:
            await asyncio.sleep(0.5)  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
            current_size = self.queue.qsize()
            if current_size > 0:
                elapsed = time.time() - start_time
                print(f"Consumer: queue prefilling... {current_size}/{min_samples} samples "
                      f"(elapsed: {elapsed:.1f}s)")
        
        final_size = self.queue.qsize()
        total_time = time.time() - start_time
        print(f"Consumer: queue ready with {final_size} samples (prefill took {total_time:.1f}s)")
        print(f"Training can now start immediately - async decoupling achieved!")
        
    async def get_batch(self, batch_size: int) -> List[MySample]:
        """
        1. éé˜»å¡è·å–ï¼šä¼˜å…ˆä»é˜Ÿåˆ—å¿«é€Ÿè·å–å·²æœ‰æ•°æ®
        2. åªåœ¨å¿…è¦æ—¶çŸ­æš‚ç­‰å¾…
        3. éƒ¨åˆ†è¿”å›ï¼šå³ä½¿æ•°æ®ä¸è¶³ä¹Ÿè¿”å›å·²æœ‰æ•°æ®ï¼Œé¿å…é˜»å¡è®­ç»ƒ
        4. é›¶æµªè´¹ï¼šç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½è¢«æ¶ˆè´¹
        Args:
            batch_size: éœ€è¦çš„æ•°æ®é‡
            
        Returns:
            List[MySample]: è·å–åˆ°çš„æ•°æ®ï¼ˆå¯èƒ½å°‘äºè¯·æ±‚é‡ï¼‰
        """
        batch = []
        start_time = time.time()
        
        print(f"Consumer: requesting {batch_size} samples from queue...")
        
        while len(batch) < batch_size:
            try:
                # éé˜»å¡è·å–ï¼ˆget_nowaitï¼‰ç¡®ä¿äº†æ¶ˆè´¹è€…ä¸ä¼šå› ä¸ºç­‰å¾…æ•°æ®ç”Ÿæˆè€Œé˜»å¡
                data = self.queue.get_nowait()
                
                if data is None:
                    self.is_finished = True
                    print("Consumer: received end signal from producer")
                    break
                
                # å°†è·å–çš„æ•°æ®æ·»åŠ åˆ°æ‰¹æ¬¡ä¸­
                batch.extend(data)
                print(f"Consumer: got {len(data)} samples from queue, batch now has {len(batch)} samples")
                
            except asyncio.QueueEmpty:
                # é˜Ÿåˆ—æš‚æ—¶ä¸ºç©º
                if batch:
                    # å·²æœ‰éƒ¨åˆ†æ•°æ®ï¼Œç«‹å³è¿”å›é¿å…é˜»å¡è®­ç»ƒ
                    print(f"Consumer: queue empty, returning {len(batch)} samples immediately (requested {batch_size})")
                    print("   - This demonstrates async decoupling: training continues with available data")
                    break
                else:
                    # ğŸ”„ å®Œå…¨æ²¡æœ‰æ•°æ®ï¼ŒçŸ­æš‚ç­‰å¾…ä½†ä¸é•¿æ—¶é—´é˜»å¡
                    print("Consumer: no data available, brief wait...")
                    await asyncio.sleep(0.1)  # å¾ˆçŸ­çš„ç­‰å¾…æ—¶é—´
                    
                    # å†æ¬¡å°è¯•è·å–ï¼Œä½†è®¾ç½®è¶…æ—¶é¿å…é•¿æ—¶é—´é˜»å¡
                    try:
                        data = await asyncio.wait_for(self.queue.get(), timeout=0.5)
                        if data is None:
                            self.is_finished = True
                            print("Consumer: received end signal during wait")
                            break
                        batch.extend(data)
                        print(f"Consumer: got {len(data)} samples after brief wait")
                    except asyncio.TimeoutError:
                        # è¶…æ—¶äº†ï¼Œä½†è¿™ä¸æ˜¯é”™è¯¯ï¼Œç»§ç»­å°è¯•
                        if not self.is_finished:
                            print(f"Consumer: timeout waiting for data, queue size: {self.queue.qsize()}")
                            print("   - Producer may be busy generating, continuing...")
                        continue
        
        #æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.total_consumed += len(batch)
        consume_time = time.time() - start_time
        
        print(f"Consumer: consumed {len(batch)} samples in {consume_time:.3f}s")
        print(f"Total consumed: {self.total_consumed}, queue remaining: {self.queue.qsize()}")
        print(f"Async decoupling working: got data quickly from pre-filled buffer")
        
        return batch
    
    async def drain_remaining_data(self) -> List[MySample]:
        """
        1. é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰å‰©ä½™æ•°æ®éƒ½è¢«æ¶ˆè´¹
        2. æ²¡æœ‰ä»»ä½•ç”Ÿæˆçš„æ•°æ®è¢«æµªè´¹
        3. ç³»ç»Ÿèµ„æºå¾—åˆ°å®Œå…¨æ¸…ç†
               
        Returns:
            List[MySample]: æ‰€æœ‰å‰©ä½™çš„æ•°æ®
        """
        remaining_data = []
        print(f"Consumer: starting to drain remaining data from queue...")
        print(f"   - Current queue size: {self.queue.qsize()}")
        print(f"   - This ensures zero data waste from async production")
        
        drain_start_time = time.time()
        
        # æŒç»­æ¸…ç©ºé˜Ÿåˆ—ç›´åˆ°å®Œå…¨ä¸ºç©º
        while True:
            try:
                # éé˜»å¡è·å–å‰©ä½™æ•°æ®
                data = self.queue.get_nowait()
                
                if data is None:
                    # é‡åˆ°ç»“æŸä¿¡å·ï¼Œåœæ­¢æ¸…ç†
                    print("Consumer: encountered end signal during drain")
                    break
                    
                remaining_data.extend(data)
                print(f"Consumer: drained {len(data)} samples, total remaining: {len(remaining_data)}")
                
            except asyncio.QueueEmpty:
                # é˜Ÿåˆ—å·²ç©ºï¼Œæ¸…ç†å®Œæˆ
                print("Consumer: queue is now empty, drain complete")
                break
        
        # æ›´æ–°æœ€ç»ˆç»Ÿè®¡
        self.total_consumed += len(remaining_data)
        drain_time = time.time() - drain_start_time
        
        print(f"Consumer: drain complete in {drain_time:.3f}s")
        print(f"Final statistics:")
        print(f"   - Total consumed: {self.total_consumed} samples")
        print(f"   - Remaining data recovered: {len(remaining_data)} samples")
        print(f"   - Zero waste achieved: ")
        
        return remaining_data
    
    async def mark_done(self, data: List[MySample]):
        """
        1. è®°å½•æ•°æ®å¤„ç†çŠ¶æ€
        2. è§¦å‘åç»­å¤„ç†é€»è¾‘
        3. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        4. æ‰§è¡Œæ¸…ç†æ“ä½œ
        
        Args:
            data: å·²å¤„ç†å®Œæˆçš„æ•°æ®
        """
        # å¯æ·»åŠ æ•°æ®å¤„ç†çš„å›è°ƒé€»è¾‘
        print(f"Consumer: marked {len(data)} samples as processed")